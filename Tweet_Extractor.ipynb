{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet_Extractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QuhrBrvnxLH02TPu7lnFwnfTtU-wXY9r",
      "authorship_tag": "ABX9TyPZ83GZVDVkQ7MZEGJbF7Q7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungeKatz/colab-notebooks/blob/main/Tweet_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqK326r8Ozjw"
      },
      "source": [
        "### Import the needed libraries \n",
        "\n",
        "\n",
        "*   tweepy to connect to twitter\n",
        "*   json for reading the keys\n",
        "*   and csv for reading/writing csv\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5aHz-sqWI5x"
      },
      "source": [
        "import json\n",
        "import tweepy\n",
        "import csv"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTaG9qbWrpq"
      },
      "source": [
        "keys = json.load(open('/content/drive/MyDrive/keys/twitterKeys.json', 'r'))\n",
        "consumer_key = keys['apiKey']\n",
        "consumer_secret = keys['apiSecretKey']\n",
        "access_key = keys['accessToken']\n",
        "access_secret = keys['accessTokenSecret']"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXUogBA_Pmkc"
      },
      "source": [
        "#### The function that extracts the tweets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tqTGy-2W6DA"
      },
      "source": [
        "def get_tweets(username):\n",
        "  auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "  auth.set_access_token(access_key, access_secret)\n",
        "  api = tweepy.API(auth)\n",
        "  number_of_tweets=500\n",
        "  all_tweets = []\n",
        "\n",
        "  tweets = api.user_timeline(screen_name=username ,  count=200,\n",
        "                           include_rts = False, tweet_mode='extended')\n",
        "  all_tweets.extend(tweets)\n",
        "  oldest_id = tweets[-1].id\n",
        "  while True:\n",
        "    tweets = api.user_timeline(screen_name=username, \n",
        "                           # 200 is the maximum allowed count\n",
        "                           count=200,\n",
        "                           include_rts = False,\n",
        "                           max_id = oldest_id - 1,\n",
        "                           # Necessary to keep full_text \n",
        "                           # otherwise only the first 140 words are extracted\n",
        "                           tweet_mode = 'extended'\n",
        "                           )\n",
        "    if len(tweets) == 0:\n",
        "        break\n",
        "    oldest_id = tweets[-1].id\n",
        "    all_tweets.extend(tweets)\n",
        "    # print('N of tweets downloaded till now {}'.format(len(all_tweets)))\n",
        "\n",
        "  #print(tweets)\n",
        "  tmp=[]\n",
        "  tweets_for_csv = [tweet.full_text for tweet in all_tweets] # CSV file created\n",
        "  for j in tweets_for_csv:\n",
        "    tmp.append(j)\n",
        "  # print(tmp)\n",
        "  return tmp\n",
        "    \n",
        "  \n",
        "\t\n",
        "\t"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ggk_aoMPo8e"
      },
      "source": [
        "#### Calling the function and adding tweets to an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxnM9Zu_YE-2"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "\t# Here goes the twitter handle for the user\n",
        "\t# whose tweets are to be extracted.\n",
        "  combined_array =[]\n",
        "  # more users can be added to this array and their tweets can be saved\n",
        "  users = ['jungekatz']\n",
        "  for user in users:\n",
        "   tweet_array=get_tweets(user)\n",
        "   for tweet in tweet_array:\n",
        "    # print(tweet)\n",
        "    combined_array.append([tweet])\n",
        "   "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuIF777mePLU"
      },
      "source": [
        "header =[\"tweet\"]\n",
        "data = combined_array\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6aqV7R4P5X0"
      },
      "source": [
        "#### Writing the tweets to csv file and saving to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "borDPZ1EeulU"
      },
      "source": [
        "with open('/content/drive/MyDrive/nlp/extract.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "   writer = csv.writer(f)\n",
        "   writer.writerow(header)\n",
        "   writer.writerows(data)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITXE0--0jp64"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    }
  ]
}